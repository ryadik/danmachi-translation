# Script-Orchestrator для перевода текстов

Этот проект представляет собой автоматизированный скрипт-оркестратор на Python, предназначенный для многоэтапной обработки и перевода больших текстовых файлов с использованием `gemini-cli`. Система спроектирована с упором на отказоустойчивость, параллелизацию, расширяемость и высокое качество итогового текста.

### ВАЖНО
**Мне абсолютно не хотелось заморачиваться и писать воркеры на ноде, так что я _полностью навайбил_ (через Gemini 2.5 pro) скрипт на змее, поэтому какое качество кода, я без понятия. Заточен только под перевод данного тайтла.**

## Основные возможности

- **Интеллектуальное разделение глав**: Автоматически разбивает большие текстовые файлы на небольшие, семантически связанные части (`chunk_*.txt`) для обработки.
- **Трехэтапный конвейер**:
  1.  **Этап `discovery` (Поиск терминов)**: Параллельно обрабатывает все чанки для обнаружения новых, ранее не известных терминов и предлагает их для добавления в основной глоссарий.
  2.  **Этап `translation` (Перевод)**: После подтверждения терминов, параллельно переводит все чанки, строго следуя глоссарию и стайлгайду.
  3.  **Этап `reading` (Вычитка)**: Проводит финальную, "полирующую" обработку уже переведенного русского текста для улучшения литературного слога, исправления стилистических ошибок и обеспечения полного соответствия стайлгайду.
- **Параллельная обработка**: Запускает несколько процессов `gemini-cli` одновременно для каждого этапа, чтобы значительно ускорить обработку.
- **Иерархическая файловая система**: Отслеживает состояние каждого чанка на каждом этапе через четкую и логичную структуру папок (`steps/discovery/pending`, `steps/translation/done` и т.д.), что обеспечивает наглядность и отказоустойчивость.
- **Полная отказоустойчивость**:
  - **Блокировка (Locking)**: Предотвращает одновременный запуск двух процессов для одной и той же главы.
  - **Чекпоинты (Checkpoints)**: Создает файлы-маркеры (`.stage_*_complete`) после успешного завершения каждого этапа, позволяя при перезапуске пропускать уже выполненную работу.
  - **Возобновление (`--resume`)**: Позволяет безопасно возобновить прерванный процесс с того места, где он остановился.
- **Продвинутая система логирования**: В режиме отладки (`--debug`) создает подробные логи для каждого аспекта работы: системные события, полные тексты промптов для каждого воркера и их ответы.

---

## Руководство пользователя

### 1. Предварительные требования

- **Python 3.x**.
- **`gemini-cli`**: Утилита должна быть установлена и авторизована (`gemini auth`).

### 2. Структура файлов и директорий

- `text/chapters/<имя_главы>/jp.txt`: Исходный текстовый файл для перевода.
- `text/chapters/<имя_главы>/ru.txt`: **Итоговый файл** с финальным, вычитанным переводом.
- `data/glossary.json`: Основной глоссарий проекта.
- `data/style_guide.md`: Правила стиля, которым должен следовать перевод и вычитка.
- `translator/prompts/`: Папка с промптами для каждого этапа (`term_discovery.txt`, `translation.txt`, `proofreading.txt`).
- `translator/config.json`: Главный файл конфигурации.
- `translator/workspace/`: Рабочая директория, где происходит вся обработка.
    - `workspace/<имя_главы>/steps/`: Содержит папки для каждого этапа (`discovery`, `translation`, `reading`), внутри которых находятся подпапки `pending`, `in_progress`, `done`, `failed`.
    - `workspace/<имя_главы>/logs/`: (Только в `--debug` режиме) Содержит подробные логи (`system_output.log`, `workers_input.log`, `workers_output.log`).
    - `workspace/<имя_главы>/terms/`: Содержит JSON-файлы с найденными терминами от воркеров.

### 3. Конфигурация (`translator/config.json`)

Основная настройка работы скрипта производится через этот файл. Для удобства также создан `config.template.json` с подробными комментариями к каждому параметру.

- **`workspace_dir`**
  - **Назначение:** Путь к корневой директории, где будут создаваться временные папки для обработки каждой главы.
  - **Пример:** `"translator/workspace"`

- **`max_concurrent_workers`**
  - **Назначение:** **(Критически важный параметр)** Определяет, сколько процессов `gemini-cli` будет запущено одновременно. Слишком большое значение может привести к быстрому исчерпанию лимитов на запросы. Стандартные ограничения:
    - RPS = 2
    - RPM = 60
    - RPD = 1000
  - **Рекомендация:** Для бесплатных аккаунтов рекомендуется значение `3` или `4`.

- **`chapter_splitter`**
  - **Назначение:** Блок настроек для "умного" разделения исходного текста на чанки.
  - **`target_chunk_size`**: Желаемый средний размер одного чанка в символах. Скрипт будет стараться создавать чанки примерно такого размера, но может отклоняться, чтобы найти удачный семантический разрыв (например, конец абзаца).
  - **`max_part_chars`**: Максимально допустимый размер чанка. Если скрипт не находит хорошего места для разрыва, он принудительно разделит текст по достижении этого лимита, чтобы избежать создания слишком больших чанков.
  - **`min_chunk_size`**: Минимальный размер чанка, предотвращает создание слишком маленьких, "мусорных" чанков.

- **`gemini_cli`**
  - **Назначение:** Настройки, относящиеся к вызовам `gemini-cli`.
  - **`model`**: Модель, которая будет использоваться для всех операций. Например, `"gemini-2.5-pro"`, `"gemini-1.5-pro-latest"`.

### 4. Как использовать

#### Стандартный запуск (с автоматической очисткой)
Эта команда запускает полный трехэтапный процесс. После успешного завершения рабочая директория **будет удалена**.

```bash
python3 translator/main.py text/chapters/prologue/jp.txt
```

#### Запуск в режиме отладки (`--debug`)
Рекомендуемый режим для тестирования. Выполняет все то же самое, но **не удаляет** рабочую директорию после завершения, позволяя изучить промежуточные результаты и подробные логи.

```bash
python3 translator/main.py --debug text/chapters/prologue/jp.txt
```

#### Принудительный чистый запуск (`--force-split`)
Полностью удаляет рабочую директорию для данной главы перед запуском. Используйте, если нужно начать с самого нуля. Можно комбинировать с `--debug`.

```bash
python3 translator/main.py --debug --force-split text/chapters/prologue/jp.txt
```

#### Возобновление после сбоя (`--resume`)
Если процесс был прерван, эта команда позволит продолжить его с прерванного этапа, пропустив уже завершенные.

```bash
python3 translator/main.py --debug --resume text/chapters/prologue/jp.txt
```

### 5. Рабочий процесс

1.  Поместите исходный файл в `text/chapters/<имя_главы>/jp.txt`.
2.  Запустите скрипт, используя одну из команд выше.
3.  Если на этапе `discovery` будут найдены новые термины, скрипт остановится и предложит их для подтверждения. Вам будет доступен интерактивный редактор для каждого поля термина.
4.  Дождитесь завершения всех трех этапов.
5.  Итоговый файл `ru.txt` появится рядом с исходным `jp.txt`.

---

## Руководство для разработчиков

### Архитектура

Система построена на принципе конвейера (pipeline), где каждый из трех этапов (`discovery`, `translation`, `reading`) является независимым модулем, работающим в своей собственной изолированной среде папок внутри `steps`. Передача данных между этапами происходит через явное копирование чанков из `done` предыдущего этапа в `pending` следующего.

- **Оркестратор (`orchestrator.py`):** Управляет общей последовательностью выполнения конвейера, вызывает воркеры для каждого этапа, проверяет чекпоинты и передает данные между этапами.
- **Менеджер задач (`task_manager.py`):** Отвечает за все операции с файловой системой: создание иерархической структуры директорий, перемещение и копирование чанков.
- **Воркеры:** В роли воркеров выступают дочерние процессы `gemini-cli`, которые выполняют задачи, определенные в промптах. Каждому воркеру присваивается уникальный ID для сквозного логирования.

### Жизненный цикл чанка

1.  **Разделение:** `chapter_splitter` создает `chunk_N.txt` в `steps/discovery/pending/`.
2.  **Этап 1 (Discovery):**
    *   Воркер обрабатывает `chunk_N.txt` из `discovery/pending`.
    *   JSON с терминами сохраняется в общую папку `terms/`.
    *   Исходный чанк `chunk_N.txt` перемещается в `steps/discovery/done/` для сохранения оригинала.
3.  **Переход:** `task_manager` копирует `chunk_N.txt` из `steps/discovery/done/` в `steps/translation/pending/`.
4.  **Этап 2 (Translation):**
    *   Воркер обрабатывает `chunk_N.txt` (оригинальный текст) из `translation/pending`.
    *   Результат (переведенный текст) сохраняется в новый файл `chunk_N.txt` в `steps/translation/done/`.
5.  **Переход:** `task_manager` копирует `chunk_N.txt` (уже с русским текстом) из `steps/translation/done/` в `steps/reading/pending/`.
6.  **Этап 3 (Reading):**
    *   Воркер обрабатывает `chunk_N.txt` (русский текст) из `reading/pending`.
    *   Результат (отполированный текст) сохраняется в новый файл `chunk_N.txt` в `steps/reading/done/`.
7.  **Сборка:** `orchestrator` собирает финальный `ru.txt` из файлов `chunk_N.txt` в папке `steps/reading/done/`.

## Идеи для реализации:

Ближайшие планы:

- [x] отладка и доработка взаимодейтсвия с глоссарием
  - [x] избавления от дубликатов типа "Айз" и "Айз Валенштайн" (это один персонаж но записей две)
  - [x] чnо есть термин? ясно определить, что не надо выводить как термин.
- [x] добавить единый логгер
- [x] сделать удаление `workspace` поумолчанию и убрать флаг `--cleanup`
- [x] добавить флаг `--debug` для того, чтобы `workspace` не удалялась после завершения
- [x] организовать структуру логов для воркспейса
- [x] класть переведенный тест рядом с японским, а не в корень.
- [x] флаги на рабочий процесс, для страта сразу с нужного жтапа
- [x] реализация работы из любого места
- [x] рефакторинг промпта на перевод (чтобы соответствовал стайлгайду).
- [x] рефакторинг структуры рабочего процесса и организации `workspace`
- [x] этап вычитки
  - [x] полный анализ и исправление текста на соответсвтие стайлгаду
  - [x] улучшение литературности и читаемости текста.

Долгосрочные планы:
- [ ] вынос в отдельный репозиторий
- [ ] yolo режим
- [ ] унификация глоссария (безконтекстный формат `[Термин] - [Перовод]`)
- [ ] автогенерация информации о мире на основе web_search
- [ ] промпты для разных языков
- [ ] сделать из скрипта - утилиту